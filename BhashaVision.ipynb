{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyjCNFlDu4tai8w9iJc9T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyO2JmRetLDS"
      },
      "outputs": [],
      "source": [
        "!pip install gradio langdetect pytesseract --quiet\n",
        "!pip install pytesseract --quiet\n",
        "!pip install langdetect --quiet\n",
        "!pip install google   --quiet\n",
        "\n",
        "!apt-get update > /dev/null   --quiet\n",
        "!apt-get install -y tesseract-ocr > /dev/null  --quiet\n",
        "!pip install pytesseract langdetect > /dev/null  --quiet\n",
        "\n",
        "!pip install langdetect pytesseract --quiet\n",
        "!apt-get install -y tesseract-ocr   --quiet\n",
        "!git clone https://github.com/tesseract-ocr/tessdata_best.git\n",
        "!cp tessdata_best/hin.traineddata /usr/share/tesseract-ocr/4.00/tessdata/\n",
        "!cp tessdata_best/eng.traineddata /usr/share/tesseract-ocr/4.00/tessdata/\n",
        "!pip install gradio langid pytesseract opencv-python --quiet\n",
        "\n",
        "!apt-get update   --quiet\n",
        "!apt-get install -y tesseract-ocr \\\n",
        "  tesseract-ocr-eng tesseract-ocr-hin tesseract-ocr-ben \\\n",
        "  tesseract-ocr-tam tesseract-ocr-tel tesseract-ocr-guj \\\n",
        "  tesseract-ocr-mar tesseract-ocr-kan tesseract-ocr-mal \\\n",
        "  tesseract-ocr-ori tesseract-ocr-asm tesseract-ocr-pan \\\n",
        "  tesseract-ocr-san tesseract-ocr-snd   --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "from langdetect import detect\n",
        "import langid\n",
        "import numpy as np\n",
        "\n",
        "# Default Tesseract model path\n",
        "DEFAULT_TESSDATA = \"/usr/share/tesseract-ocr/4.00/tessdata/\"\n",
        "# Update this path to where tessdata_best is located on your system\n",
        "BEST_TESSDATA = \"/content/tessdata_best/\"\n",
        "\n",
        "# Define language codes for Tesseract OCR\n",
        "INDIAN_LANGS = \"eng+hin+ben+tam+tel+guj+mar+kan+mal+ori+asm+pan+san+sat+snd\"\n",
        "\n",
        "# Map language codes to full language names\n",
        "LANGUAGE_NAME_MAP = {\n",
        "    \"en\": \"English\", \"hi\": \"Hindi\", \"bn\": \"Bengali\", \"ta\": \"Tamil\",\n",
        "    \"te\": \"Telugu\", \"ml\": \"Malayalam\", \"gu\": \"Gujarati\", \"mr\": \"Marathi\",\n",
        "    \"kn\": \"Kannada\", \"or\": \"Odia\", \"as\": \"Assamese\", \"pa\": \"Punjabi\",\n",
        "    \"sa\": \"Sanskrit\", \"sat\": \"Santali\", \"sd\": \"Sindhi\", \"und\": \"Unknown\"\n",
        "}\n",
        "\n",
        "def is_blurry(image):\n",
        "    \"\"\"Check if the image is blurry based on Laplacian variance.\"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "    return fm < 80  # Lower value means blurrier\n",
        "\n",
        "def enhance_if_blurry(img):\n",
        "    \"\"\"Apply minimal sharpening if image is blurry.\"\"\"\n",
        "    if is_blurry(img):\n",
        "        print(\"Applying blur correction...\")\n",
        "        kernel = np.array([[0, -1, 0],\n",
        "                           [-1, 5, -1],\n",
        "                           [0, -1, 0]])\n",
        "        return cv2.filter2D(img, -1, kernel)\n",
        "    return img\n",
        "\n",
        "def process_image(image, detection_method, tess_model):\n",
        "    \"\"\"\n",
        "    Process the uploaded image:\n",
        "      - Optionally enhance blurry images.\n",
        "      - Set Tesseract model directory based on selection.\n",
        "      - Perform OCR with Tesseract.\n",
        "      - Detect language for each text region using the selected method (langdetect or langid).\n",
        "      - Draw bounding boxes with language labels.\n",
        "    \"\"\"\n",
        "    # Set Tesseract tessdata path based on user selection\n",
        "    if tess_model == \"tessdata_best\":\n",
        "        os.environ[\"TESSDATA_PREFIX\"] = BEST_TESSDATA\n",
        "    else:\n",
        "        os.environ[\"TESSDATA_PREFIX\"] = DEFAULT_TESSDATA\n",
        "\n",
        "    detected_languages = set()\n",
        "    img_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "    img_bgr = enhance_if_blurry(img_bgr)\n",
        "\n",
        "    # Convert image to grayscale for OCR\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    recognized_text = pytesseract.image_to_string(gray, lang=INDIAN_LANGS)\n",
        "\n",
        "    data = pytesseract.image_to_data(img_bgr, lang=INDIAN_LANGS, output_type=Output.DICT)\n",
        "    n_boxes = len(data[\"text\"])\n",
        "\n",
        "    for i in range(n_boxes):\n",
        "        try:\n",
        "            conf = float(data[\"conf\"][i])\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        if conf > 60:\n",
        "            word = data[\"text\"][i].strip()\n",
        "            if len(word) >= 3:\n",
        "                try:\n",
        "                    if detection_method == \"langdetect\":\n",
        "                        lang_code = detect(word)\n",
        "                    elif detection_method == \"langid\":\n",
        "                        lang_code = langid.classify(word)[0]\n",
        "                    else:\n",
        "                        lang_code = \"und\"\n",
        "                except Exception:\n",
        "                    lang_code = \"und\"\n",
        "\n",
        "                lang_name = LANGUAGE_NAME_MAP.get(lang_code, \"Unknown\")\n",
        "                detected_languages.add(lang_name)\n",
        "                x, y, w, h = int(data[\"left\"][i]), int(data[\"top\"][i]), int(data[\"width\"][i]), int(data[\"height\"][i])\n",
        "                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(img_bgr, lang_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.6, (255, 0, 0), 2)\n",
        "\n",
        "    annotated_img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    languages_bullets = \"\\n\".join(\"- \" + lang for lang in sorted(detected_languages))\n",
        "    return recognized_text.strip(), annotated_img, languages_bullets\n",
        "\n",
        "# Define components using updated Gradio syntax\n",
        "image_input = gr.Image(type=\"numpy\", label=\"Upload Image (even blurry)\")\n",
        "detection_dropdown = gr.Dropdown(choices=[\"langdetect\", \"langid\"], value=\"langdetect\",\n",
        "                                 label=\"Select Language Detection Method\")\n",
        "tess_model_dropdown = gr.Dropdown(choices=[\"default\", \"tessdata_best\"], value=\"default\",\n",
        "                                  label=\"Select Tesseract Model\")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_image,\n",
        "    inputs=[image_input, detection_dropdown, tess_model_dropdown],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Extracted Text\"),\n",
        "        gr.Image(type=\"numpy\", label=\"Annotated Image\"),\n",
        "        gr.Textbox(label=\"Detected Languages\")\n",
        "    ],\n",
        "    title=\"Multilingual OCR with Tesseract Model Support\",\n",
        "    description=(\"Extracts text from images (even blurry) and detects languages using \"\n",
        "                 \"either langdetect or langid. Select the Tesseract model to use for OCR accuracy. \"\n",
        "                 \"For better accuracy, choose tessdata_best if available.\")\n",
        ")\n",
        "\n",
        "iface.launch(pwa=True,debug=True)\n"
      ],
      "metadata": {
        "id": "566wbpNgtaDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}